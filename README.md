# FIAP - Faculdade de Inform√°tica e Administra√ß√£o Paulista

<p align="center">
<a href= "https://www.fiap.com.br/"><img src="assets/logo-fiap.png" alt="FIAP - Faculdade de Inform√°tica e Admnistra√ß√£o Paulista" border="0" width=40% height=40%></a>
</p>

<br>

# FIAP Fase6_Cap 1 - Despertar da rede neural


## üë®‚Äçüéì Integrantes: 
- <a href="https://www.linkedin.com/in/amanda-fragnan-b61537255/" target="_blank">Amanda Fragnan RM 555684 </a>
- <a href="https://www.linkedin.com/in/cunhaandre/" target="_blank">Andre Cunha RM 560648</a>
- <a href="https://www.linkedin.com/in/gabriellehalasc/" target="_blank">Gabrielle Halasc RM 560147</a> 

## üë©‚Äçüè´ Professores:
### Tutor(a)
- <a href="https://www.linkedin.com/in/lucas-gomes-moreira-15a8452a/">Lucas Gomes Moreira</a>
### Coordenador(a)
- <a href="https://www.linkedin.com/in/profandregodoi/">Andr√© Godoi</a>

# Entregavel 1:

## üìú Descri√ß√£o

Projeto: Despertar da rede neural, Visao Computacional

üéØ Objetivo Geral 

Este projeto tem como objetivo demonstrar a implementa√ß√£o de um sistema de vis√£o computacional utilizando o modelo YOLO (You Only Look Once), com foco na identifica√ß√£o e classifica√ß√£o de objetos em imagens. O modelo foi treinado para identificar dois tipos de objetos, baseando-se em um dataset com imagens de dois objetos distintos.
Criar um sistema de vis√£o computacional com YOLO, aplicando-o em um cen√°rio pr√°tico de monitoramento e reconhecimento de objetos em imagens. O sistema ser√° utilizado pela FarmTech Solutions para mostrar o potencial da IA nas √°reas de seguran√ßa patrimonial e sa√∫de animal.

## üìä Documenta√ß√£o do Processo de Prepara√ß√£o dos Dados

1. Organiza√ß√£o do Dataset
O dataset foi composto por:

- Objeto A: 40 imagens (32 para treinamento, 4 para valida√ß√£o, 4 para teste)

- Objeto B: 40 imagens (32 para treinamento, 4 para valida√ß√£o, 4 para teste)

As imagens foram armazenadas no Google Drive e rotuladas utilizando o site Make Sense IA.
*Dados coletados no Google e armazenados no Colab*

2. Treinamento, Valida√ß√£o e Teste
O treinamento foi feito utilizando a YOLO adapt√°vel, conforme explicado no cap√≠tulo 3 de Redes Neurais. O modelo foi treinado com diferentes n√∫meros de √©pocas, e os resultados de desempenho foram avaliados.

3. Compara√ß√£o de Resultados
Foram realizadas duas simula√ß√µes com diferentes quantidades de √©pocas (30 e 60), e os resultados de acur√°cia, erro e desempenho foram comparados.


## üß† Resultados e Analise

### Treinamento com 30 √âpocas

Precis√£o m√©dia (P): 60%

Recall m√©dio (R): 71.7%

mAP@50: 62.4%

### Treinamento com 60 √âpocas
Precis√£o m√©dia (P): 69.5%

Recall m√©dio (R): 74.5%

mAP@50: 66.7%

mAP@50-95: 54.4%

### Conclus√£o:
1. Melhor Desempenho nas 60 √âpocas:
Precision e Recall: O modelo alcan√ßou melhores valores de precis√£o e recall ap√≥s 60 √©pocas, tanto para o trator quanto para a casa, em compara√ß√£o com 40 √©pocas. Isso indica que o modelo ficou mais preciso e capaz de identificar corretamente os objetos.

mAP50: A m√©dia de precis√£o nas imagens (mAP@50) aumentou, o que significa que a qualidade das detec√ß√µes melhorou nas 60 √©pocas.

mAP50-95: O mAP@50-95, que √© uma m√©dia de precis√£o ao longo de m√∫ltiplos limiares de IOU, tamb√©m apresentou um aumento significativo (de 0.421 para 0.544). Isso mostra uma melhoria geral no desempenho do modelo em diferentes limiares.

2. Tratores vs Casas:
O desempenho com tratores foi melhor tanto em precis√£o quanto em recall, provavelmente porque o modelo teve mais exemplos de tratores, o que ajudou no aprendizado. J√° para as casas, o modelo tem um desempenho razo√°vel, com uma boa precis√£o, mas poderia melhorar ainda mais.

*Mais experimentos s√£o necess√°rios para otimizar ainda mais o modelo, com mais dados e ajustes finos.*



## üñºÔ∏è Prints dos resultados

üìå Imagem trator

![image](https://github.com/user-attachments/assets/49645ecf-8c44-483c-92ec-bc45f1d04987)


üìå Imagem casa

![image](https://github.com/user-attachments/assets/b6fda0f6-67dd-45ee-8025-db4a7c5a8c14)


## üìä Link video

https://youtu.be/i6o_5E1ckbo

# üìë Entrega 2 - Comparativo de Modelos de Vis√£o Computacional

## Objetivo

O objetivo desta entrega foi comparar a performance de tr√™s abordagens de redes neurais em Vis√£o Computacional aplicadas a um problema de detec√ß√£o de objetos e classifica√ß√£o de imagens:

- **YOLO Adapt√°vel** (treinado na Entrega 1)
- **YOLO Tradicional** (modelo pr√©-treinado)
- **CNN Treinada do Zero**

## 1. YOLO Adapt√°vel - Resultados da Entrega 1

### ‚ö° Resultados

- **Precis√£o**: 0.88 (40 epochs) / 0.91 (60 epochs)
- **Tempo de treinamento**: 30 minutos (40 epochs) / 45 minutos (60 epochs)
- **Tempo de infer√™ncia**: ~0.05s por imagem

## 2. YOLO Tradicional (Modelo Pr√©-treinado)

### ‚ö° Resultados

- **Precis√£o**: Baixa (n√£o detectou objetos da base)
- **Tempo de infer√™ncia**: ~0.45s por imagem

O modelo YOLOv5s pr√©-treinado foi carregado diretamente do reposit√≥rio e utilizado sem adapta√ß√µes, mas teve problemas de detec√ß√£o de objetos da nossa base de dados espec√≠fica.

## 3. CNN Treinada do Zero (Classifica√ß√£o)

### ‚ö° Resultados

- **Precis√£o**: 1.00
- **Tempo de treinamento**: Muito r√°pido (~20 segundos para 10 epochs)
- **Tempo de infer√™ncia**: ~0.26s por imagem

A CNN treinada do zero obteve uma precis√£o perfeita (1.00), mas isso se deve ao fato de o dataset ser simples e pequeno, o que pode ter causado overfitting.

## üìù Comparativo dos Modelos

| Crit√©rio                      | YOLO Adapt√°vel (Entrega 1) | YOLO Tradicional (pr√©-treinado) | CNN do Zero |
|:-------------------------------|:---------------------------|:-------------------------------|:------------|
| **Facilidade de uso/integra√ß√£o**   | M√©dia (requer adapta√ß√£o e treinamento) | Alta (modelo pr√©-treinado, f√°cil de usar) | M√©dia (requer prepara√ß√£o de dataset e treinamento do zero) |
| **Precis√£o**                       | 0.88 (40 epochs) / 0.91 (60 epochs) | Baixa (n√£o detectou objetos da base) | 1.00 |
| **Tempo de treinamento**           | 30 min (40 epochs) / 45 min (60 epochs) | Nenhum (pr√©-treinado) | Muito r√°pido (cerca de 20 segundos para 10 epochs) |
| **Tempo de infer√™ncia**            | ~0.05s por imagem | ~0.45s por imagem | ~0.26s por imagem |

##  üß† Discuss√£o Cr√≠tica

- **YOLO Adapt√°vel**:  
  Treinar a YOLO personalizada foi um pouco mais trabalhoso, pois exigiu preparar a base de dados, treinar o modelo e ajustar hiperpar√¢metros. Contudo, obteve uma boa precis√£o de **88%** (40 epochs) e at√© **91%** (60 epochs). O tempo de infer√™ncia foi excelente (~0.05s/imagem), o que torna a YOLO adapt√°vel uma boa op√ß√£o para aplica√ß√µes em tempo real, desde que se aceite o custo de treinamento.

- **YOLO Tradicional (pr√©-treinado)**:  
  Apesar da facilidade de uso, o modelo YOLOv5s pr√©-treinado n√£o foi capaz de detectar corretamente os objetos da base, evidenciando a limita√ß√£o de modelos gen√©ricos quando aplicados a problemas muito espec√≠ficos. O tempo de infer√™ncia foi mais alto (~0.45s/imagem), especialmente por ser executado na CPU.

- **CNN Treinada do Zero**:  
  A CNN simples foi muito r√°pida para treinar e atingiu **100% de acur√°cia** no treino e teste. Esse resultado √© esperado devido ao pequeno tamanho do dataset, o que facilitou o overfitting. Para problemas de classifica√ß√£o de imagens em poucas classes, a CNN √© eficiente e r√°pida, mas em detec√ß√£o de objetos em maior escala, precisaria de adapta√ß√µes.

---

** ‚úÖ Conclus√£o**:  
As tr√™s abordagens t√™m suas vantagens e limita√ß√µes. Para uma aplica√ß√£o mais gen√©rica, a **YOLO Tradicional** pode ser √∫til, mas precisa ser adaptada para novos datasets. A **YOLO Adapt√°vel** √© excelente para um desempenho em tempo real, enquanto a **CNN** treinada do zero tem um √≥timo desempenho em tarefas simples de classifica√ß√£o, mas sofre com limita√ß√µes para detec√ß√£o de objetos complexos.

---
## üìä Link Colab
https://colab.research.google.com/drive/11KJO-xJNTmtUHW_XQa9RU60F-sF1m9kL#scrollTo=DQd-wYCEz45M

## üìÅ Estrutura de pastas

Dentre os arquivos e pastas presentes na raiz do projeto, definem-se:

- fase6.py: C√≥digo Python contendo o primeiro entregavel do projeto.

- entregavel2.py: C√≥digo Python contendo o segundo entregavel do projeto.

- LEIA-ME.md: Documento que funciona como um guia geral do projeto, apresentando seus objetivos, estrutura, funcionamento e instru√ß√µes de uso. Este √© o arquivo de leitura inicial para novos usu√°rios.


## üîß Como executar o c√≥digo

1. Clonar o reposit√≥rio

Primeiro, fa√ßa o clone deste reposit√≥rio localmente usando o Git:

git clone https://github.com/GabrielleHalasc/FIAP-FASE6-CAP1.git

2. Instalar depend√™ncias

Certifique-se de ter todas as depend√™ncias instaladas. Se estiver usando Python, voc√™ pode instalar os pacotes necess√°rios com:

pip install -r requirements.txt

3. Executar o c√≥digo
   
## Historico de lan√ßamentos

- <b> 0.1.0 - 28/04/2025<b>
- <b> 0.2.0 - 29/04/2025<b>
  
## üìã Licen√ßa

<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"><p xmlns:cc="http://creativecommons.org/ns#" xmlns:dct="http://purl.org/dc/terms/"><a property="dct:title" rel="cc:attributionURL" href="https://github.com/agodoi/template">MODELO GIT FIAP</a> por <a rel="cc:attributionURL dct:creator" property="cc:attributionName" href="https://fiap.com.br">Fiap</a> est√° licenciado sobre <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">Attribution 4.0 International</a>.</p>
